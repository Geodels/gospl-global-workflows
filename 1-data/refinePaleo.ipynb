{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pygmt\n",
    "import struct\n",
    "import imageio\n",
    "import pygplates\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import cartopy.crs as ccrs\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.spatial.transform import Rotation as scpRot\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb17301",
   "metadata": {},
   "source": [
    "This notebook builds a temporally refined paleo-elevation reconstruction for a coarser one. \n",
    "\n",
    "Here as an example we build a 1Ma paleo-elevation model out of a 5Ma interval one.\n",
    "\n",
    "We first define a set of functions to perform the smaller time stepping interpolation using a backward/forward approach..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ce083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPaleoTopo(dem_folder, time):\n",
    "    # Get the paleosurface mesh file (as netcdf file)\n",
    "    paleoDemsPath = Path(dem_folder)\n",
    "    initialLandscapePath = list(paleoDemsPath.glob(\"**/%dMa.nc\" % int(time)))[0]\n",
    "    # Open it with xarray\n",
    "    data = xr.open_dataset(initialLandscapePath)\n",
    "    return data.sortby(data.latitude)\n",
    "\n",
    "def getPaleoRain(rain_folder, time, glon, glat):\n",
    "    # Get the paleosurface mesh file (as netcdf file)\n",
    "    paleoRainPath = Path(rain_folder)\n",
    "    initialRainPath = list(paleoRainPath.glob(\"**/%dMa.nc\" % int(time)))[0]\n",
    "    # Open it with xarray\n",
    "    data = xr.open_dataset(initialRainPath)\n",
    "    datai = data.interp(lat=glat, lon=glon)\n",
    "    return datai.sortby(data.lat)\n",
    "\n",
    "def getPlateIDs(plate_folder, time, lonlat):\n",
    "    # Read plate IDs from gPlates exports\n",
    "    velfile = plate_folder + \"vel\" + str(int(time)) + \"Ma.xy\"\n",
    "    data = pd.read_csv(\n",
    "        velfile,\n",
    "        sep=r\"\\s+\",\n",
    "        engine=\"c\",\n",
    "        header=None,\n",
    "        na_filter=False,\n",
    "        dtype=float,\n",
    "        low_memory=False,\n",
    "    )\n",
    "    data = data.drop_duplicates().reset_index(drop=True)\n",
    "    llvel = data.iloc[:, 0:2].to_numpy()\n",
    "    gplateID = data.iloc[:, -1].to_numpy().astype(int)\n",
    "    vtree = cKDTree(llvel)\n",
    "    dist, ids = vtree.query(lonlat, k=1)\n",
    "   \n",
    "    return gplateID[ids]\n",
    "\n",
    "def polarToCartesian(radius, theta, phi, useLonLat=True):\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.radians(theta+180.), np.radians(90. - phi)\n",
    "    X = radius * np.cos(theta) * np.sin(phi)\n",
    "    Y = radius * np.sin(theta) * np.sin(phi)\n",
    "    Z = radius * np.cos(phi)\n",
    "    \n",
    "    #Return data either as a list of XYZ coordinates or as a single XYZ coordinate\n",
    "    if (type(X) == np.ndarray):\n",
    "        return np.stack((X, Y, Z), axis=1)\n",
    "    else:\n",
    "        return np.array([X, Y, Z])\n",
    "\n",
    "def cartesianToPolarCoords(XYZ, useLonLat=True):\n",
    "    X, Y, Z = XYZ[:, 0], XYZ[:, 1], XYZ[:, 2]\n",
    "    R = (X**2 + Y**2 + Z**2)**0.5\n",
    "    theta = np.arctan2(Y, X)\n",
    "    phi = np.arccos(Z / R)\n",
    "    \n",
    "    #Return results either in spherical polar or leave it in radians\n",
    "    if useLonLat == True:\n",
    "        theta, phi = np.degrees(theta), np.degrees(phi)\n",
    "        lon, lat = theta - 180, 90 - phi\n",
    "        lon[lon < -180] = lon[lon < -180] + 360\n",
    "        return R, lon, lat\n",
    "    else:\n",
    "        return R, theta, phi\n",
    "\n",
    "def quaternion(axis, angle):\n",
    "    return [np.sin(angle/2) * axis[0], \n",
    "            np.sin(angle/2) * axis[1], \n",
    "            np.sin(angle/2) * axis[2], \n",
    "            np.cos(angle/2)]\n",
    "\n",
    "def getRotations(time, deltaTime, plateIds, rotationModel):\n",
    "    rotations = {}\n",
    "    for plateId in np.unique(plateIds):\n",
    "        stageRotation = rotationModel.get_rotation(int(time-deltaTime), int(plateId), int(time))\n",
    "        stageRotation = stageRotation.get_euler_pole_and_angle()\n",
    "        axisLatLon = stageRotation[0].to_lat_lon()\n",
    "        axis = polarToCartesian(1, axisLatLon[1], axisLatLon[0])\n",
    "        angle = stageRotation[1]\n",
    "        rotations[plateId] = scpRot.from_quat(quaternion(axis, angle))\n",
    "    return rotations\n",
    "\n",
    "def movePlates(sphereXYZ, plateIds, rotations):\n",
    "    newXYZ = np.copy(sphereXYZ)\n",
    "    for idx in np.unique(plateIds):\n",
    "        rot = rotations[idx]\n",
    "        newXYZ[plateIds == idx] = rot.apply(newXYZ[plateIds == idx])\n",
    "    return newXYZ\n",
    "\n",
    "def interpData(data,xyz,mvxyz,ngbh=1):\n",
    "    # Build the kdtree\n",
    "    ptree = cKDTree(mvxyz)\n",
    "    distNbghs, idNbghs = ptree.query(xyz, k=ngbh)\n",
    "    if ngbh == 1:\n",
    "        return data[idNbghs]\n",
    "    \n",
    "    # Inverse weighting distance...\n",
    "    weights = np.divide(\n",
    "        1.0,\n",
    "        distNbghs,\n",
    "        out=np.zeros_like(distNbghs),\n",
    "        where=distNbghs != 0,\n",
    "    )\n",
    "    onIDs = np.where(distNbghs[:, 0] == 0)[0]\n",
    "    temp = np.sum(weights, axis=1)\n",
    "    tmp = np.sum(weights * data[idNbghs], axis=1)\n",
    "    # Elevation\n",
    "    interpZ = np.divide(\n",
    "        tmp, temp, out=np.zeros_like(temp), where=temp != 0\n",
    "    )\n",
    "    if len(onIDs) > 0:\n",
    "        interpZ[onIDs] = data[idNbghs[onIDs, 0]]\n",
    "    return interpZ\n",
    "\n",
    "def runSubProcess(args, output=True, cwd=\".\"):\n",
    "    p = subprocess.Popen(\n",
    "        args,\n",
    "        cwd=cwd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "    )\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = p.stdout.readline()\n",
    "        if not line and p.poll() is not None:\n",
    "            break\n",
    "        lines.append(line)\n",
    "        if output:\n",
    "            print(line, end=\"\")\n",
    "\n",
    "    if p.returncode != 0:\n",
    "        output = \"\".join(lines)\n",
    "        if \"ERROR: \" in output:\n",
    "            _, _, error_msg = output.partition(\"ERROR: \")\n",
    "        elif \"what()\" in output:\n",
    "            _, _, error_msg = output.partition(\"what(): \")\n",
    "        else:\n",
    "            error_msg = \"dbscan aborted unexpectedly.\"\n",
    "        error_msg = \" \".join(error_msg.split())\n",
    "\n",
    "        raise RuntimeError(error_msg)\n",
    "\n",
    "def clusterZ(time, mvxyz, elev, clustngbh=6, clustdist=10.e3, output=False, nprocs=4, cwd=\".\"):\n",
    "    if output:\n",
    "        print(\"\\ndbscan MPI\")\n",
    "    dims = [len(mvxyz), 3]\n",
    "    linepts = mvxyz.ravel()\n",
    "    lgth = len(linepts)\n",
    "    fbin = \"nodes\" + str(time) + \".bin\"\n",
    "    with open(fbin, mode=\"wb\") as f:\n",
    "        f.write(struct.pack(\"i\" * 2, *[int(i) for i in dims]))\n",
    "        f.write(struct.pack(\"f\" * (lgth), *[float(i) for i in linepts]))\n",
    "    fnc = \"clusters\" + str(time) + \".nc\"\n",
    "    mpi_args = [\n",
    "        \"mpirun\",\n",
    "        \"-np\",\n",
    "        str(nprocs),\n",
    "        \"dbscan\",\n",
    "        \"-i\",\n",
    "        fbin,\n",
    "        \"-b\",\n",
    "        \"-m\",\n",
    "        \"2\",\n",
    "        \"-e\",\n",
    "        str(clustdist),\n",
    "        \"-o\",\n",
    "        fnc,\n",
    "    ]\n",
    "    runSubProcess(mpi_args, output, cwd)\n",
    "    if output:\n",
    "        print(\"\\nGet global ID of clustered vertices\")\n",
    "    cluster = xr.open_dataset(fnc)\n",
    "    isClust = cluster.cluster_id.values > 0\n",
    "    clustPtsX = cluster.position_col_X0.values[isClust]\n",
    "    clustPtsY = cluster.position_col_X1.values[isClust]\n",
    "    clustPtsZ = cluster.position_col_X2.values[isClust]\n",
    "    clustPts = np.vstack((clustPtsX, clustPtsY))\n",
    "    clustPts = np.vstack((clustPts, clustPtsZ)).T\n",
    "    ptree = cKDTree(mvxyz)\n",
    "    dist, ids = ptree.query(clustPts, k=1)\n",
    "    isCluster = np.zeros(len(mvxyz), dtype=int)\n",
    "    isCluster[ids] = 1\n",
    "    idCluster = isCluster > 0\n",
    "    ptsCluster = mvxyz[idCluster]\n",
    "    ctree = cKDTree(ptsCluster)\n",
    "    _, clustNgbhs = ctree.query(ptsCluster, k=clustngbh)\n",
    "    clustNgbhs = clustNgbhs[:, 1:]\n",
    "    args = [\n",
    "        \"rm\",\n",
    "        fbin,\n",
    "        fnc,\n",
    "    ]\n",
    "    runSubProcess(args, output, cwd)\n",
    "\n",
    "    # Get heights of nearest neighbours\n",
    "    heightsInCluster = elev[idCluster]\n",
    "    neighbourHeights = heightsInCluster[clustNgbhs]\n",
    "\n",
    "    # For points in cluster, set new heights to the maximum height of\n",
    "    # nearest neighbours\n",
    "    clustZ = elev.copy()\n",
    "    neighbourHeights.partition(1,axis=1)\n",
    "    clustZ[idCluster] = np.mean(neighbourHeights[:,-int(clustngbh/2):], axis=1)\n",
    "\n",
    "    return clustZ\n",
    "\n",
    "def runSubProcess(args, output=True, cwd=\".\"):\n",
    "    # Launch a subprocess\n",
    "    p = subprocess.Popen(\n",
    "        args,\n",
    "        cwd=cwd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "    )\n",
    "\n",
    "    # Capture and re-print OpenMC output in real-time\n",
    "    lines = []\n",
    "    while True:\n",
    "        # If OpenMC is finished, break loop\n",
    "        line = p.stdout.readline()\n",
    "        if not line and p.poll() is not None:\n",
    "            break\n",
    "\n",
    "        lines.append(line)\n",
    "        if output:\n",
    "            # If user requested output, print to screen\n",
    "            print(line, end=\"\")\n",
    "\n",
    "    # Raise an exception if return status is non-zero\n",
    "    if p.returncode != 0:\n",
    "        # Get error message from output and simplify whitespace\n",
    "        output = \"\".join(lines)\n",
    "        if \"ERROR: \" in output:\n",
    "            _, _, error_msg = output.partition(\"ERROR: \")\n",
    "        elif \"what()\" in output:\n",
    "            _, _, error_msg = output.partition(\"what(): \")\n",
    "        else:\n",
    "            error_msg = \"dbscan aborted unexpectedly.\"\n",
    "        error_msg = \" \".join(error_msg.split())\n",
    "\n",
    "        raise RuntimeError(error_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b3fa2",
   "metadata": {},
   "source": [
    "We now define the main script that will perform either the forward or backward interpolation of the paleo-elevation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7215658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runScript(time, dt, forward=False, rain=False):\n",
    "    \n",
    "    rotation_fname = 'PALEOMAP_PlateModel.rot'\n",
    "    polygon_fname = 'PlateBoundaries.gpml'\n",
    "    dem_folder = 'ndem/'\n",
    "    rain_folder = 'rain/'\n",
    "    plate_folder = 'vel1Ma/'\n",
    "    radius = 6371*1000.\n",
    "    \n",
    "    rotationModel = pygplates.RotationModel(rotation_fname)\n",
    "    topoFeature = pygplates.FeatureCollection(polygon_fname)\n",
    "        \n",
    "    paleoZ = getPaleoTopo(dem_folder,time[0])\n",
    "    glon = paleoZ.longitude.values\n",
    "    glat = paleoZ.latitude.values\n",
    "    shape = paleoZ.z.shape\n",
    "    lons, lats = np.meshgrid(glon, glat)\n",
    "    \n",
    "    lonlat = np.empty((len(lons.ravel()),2))\n",
    "    lonlat[:,0] = lons.ravel()\n",
    "    lonlat[:,1] = lats.ravel()\n",
    "    \n",
    "    if rain:\n",
    "        paleoR = getPaleoRain(rain_folder, time[0], glon, glat)\n",
    "        \n",
    "\n",
    "    if forward:\n",
    "        out_path = 'forward'\n",
    "        out_path2 = 'backward'\n",
    "    else:\n",
    "        out_path = 'backward'\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "        \n",
    "    if rain:\n",
    "        rdata = []\n",
    "        rdata.append(paleoR)\n",
    "        newrdata = paleoR.copy()\n",
    "        newrdata = newrdata.drop_vars(names=['z'])\n",
    "        newrdata['z'] = (['lat', 'lon'],  paleoR.z.values)\n",
    "        newrdata.to_netcdf(out_path+'/nrain'+str(time[0])+'Ma.nc')\n",
    "    \n",
    "    ndata = []\n",
    "    ndata.append(paleoZ)\n",
    "    nheights = gaussian_filter(paleoZ.z.values, sigma=0.75)\n",
    "    newdata = paleoZ.copy()\n",
    "    newdata = newdata.drop_vars(names=['z'])\n",
    "    newdata['z'] = (['latitude', 'longitude'],  nheights)\n",
    "    newdata.to_netcdf(out_path+'/ndem'+str(time[0])+'Ma.nc')\n",
    "    \n",
    "    print(' + start loop',time[0])\n",
    "    val = [0.2,0.4,0.6,0.8]\n",
    "    for s in range(len(time)-1):\n",
    "    \n",
    "        plateIds = getPlateIDs(plate_folder, time[s], lonlat)\n",
    "        heights = ndata[s].z.values.ravel()\n",
    "        sphericalZ = heights + radius\n",
    "        sXYZ = polarToCartesian(sphericalZ, lonlat[:,0], lonlat[:,1])\n",
    "        rotations = getRotations(time[s], dt, plateIds, rotationModel)\n",
    "\n",
    "        movXYZ = movePlates(sXYZ, plateIds, rotations)\n",
    "        \n",
    "        nheights = clusterZ(time[s], movXYZ, heights)\n",
    "        newZ = interpData(nheights,sXYZ,movXYZ).reshape(shape)\n",
    "        \n",
    "        if rain:\n",
    "            newR = interpData(rdata[s].z.values.ravel(),sXYZ,movXYZ).reshape(shape)\n",
    "            \n",
    "        if forward:\n",
    "            bdata = xr.open_dataset(out_path2+'/ndem'+str(time[s]-dt)+'Ma.nc')\n",
    "            diff = (bdata.z.values - newZ)*val[s]\n",
    "            nheights = gaussian_filter(newZ+diff, sigma=0.75)\n",
    "            \n",
    "        data = ndata[s].copy()\n",
    "        data = data.drop_vars(names=['z'])\n",
    "        if forward:\n",
    "            data['z'] = (['latitude', 'longitude'],  nheights)\n",
    "        else:\n",
    "            data['z'] = (['latitude', 'longitude'],  newZ)\n",
    "        data.to_netcdf(out_path+'/ndem'+str(time[s]-dt)+'Ma.nc')\n",
    "        ndata.append(data)\n",
    "        \n",
    "        if rain:\n",
    "            data = rdata[s].copy()\n",
    "            data = data.drop_vars(names=['z'])\n",
    "            data['z'] = (['lat', 'lon'],  newR)\n",
    "            data.to_netcdf(out_path+'/nrain'+str(time[s]-dt)+'Ma.nc')\n",
    "            rdata.append(data)\n",
    "            \n",
    "        print('    -  done time: ',time[s]-dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53641f57",
   "metadata": {},
   "source": [
    "Define the time step from 100 Ma to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = np.arange(100,-5,-5)\n",
    "ntime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f5486",
   "metadata": {},
   "source": [
    "Perform the caculations, it will create a new series of netcdf file at 1Ma interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e745d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range(len(ntime)-1):\n",
    "    \n",
    "    # Backward \n",
    "    print('+ Backward run')\n",
    "    dt = -1\n",
    "    time = np.arange(ntime[k+1],ntime[k],-dt)\n",
    "    runScript(time,dt,forward=False,rain=False)\n",
    "\n",
    "    # Forward\n",
    "    print('+ Forward run')\n",
    "    dt = 1\n",
    "    time = np.arange(ntime[k],ntime[k+1],-dt)\n",
    "    runScript(time,dt,forward=True,rain=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3421fd",
   "metadata": {},
   "source": [
    "Copy the last paleo-elevation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\"cp\", \"backward/ndem0Ma.nc\", \"forward/\"]\n",
    "runSubProcess(args, True, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c6c24d",
   "metadata": {},
   "source": [
    "In case you ran your model with rainfall map turned-on (actually it is maybe not the best approach for climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fef852",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path1 = 'forward'\n",
    "out_path2 = 'backward'\n",
    "outf = 'comb_rain'\n",
    "\n",
    "lst = []\n",
    "for k in range(len(ntime)-1):\n",
    "    p = 0\n",
    "    for k in range(ntime[k],ntime[k+1],-1):\n",
    "        if p < 3:\n",
    "            filename = out_path1+'/nrain'+str(k)+'Ma.nc' \n",
    "            lst.append(filename)\n",
    "        else:\n",
    "            filename = out_path2+'/nrain'+str(k)+'Ma.nc' \n",
    "            lst.append(filename)\n",
    "        p += 1\n",
    "filename = out_path2+'/nrain0Ma.nc' \n",
    "lst.append(filename)\n",
    "\n",
    "args = [\"cp\", \"backward/nrain0Ma.nc\", \"forward/\"]\n",
    "runSubProcess(args, True, '.')\n",
    "\n",
    "if not os.path.exists(outf):\n",
    "    os.makedirs(outf)\n",
    "for k in range(len(lst)):\n",
    "    args = [\"cp\", lst[k], outf]\n",
    "    runSubProcess(args, True, '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1c959",
   "metadata": {},
   "source": [
    "Perform the plotting of the elevation through time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6541ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBounds(time,topology_features,rotation_model):\n",
    "    resolved_topologies = []\n",
    "    shared_boundary_sections = []\n",
    "    pygplates.resolve_topologies(topology_features, rotation_model, resolved_topologies, time, shared_boundary_sections)\n",
    "    wrapper = pygplates.DateLineWrapper(0.)\n",
    "    subductions = []\n",
    "    oceanRidges = []\n",
    "    otherBounds = []\n",
    "    for shared_boundary_section in shared_boundary_sections:\n",
    "        if shared_boundary_section.get_feature().get_feature_type() == pygplates.FeatureType.create_gpml('MidOceanRidge'):\n",
    "            for shared_sub_segment in shared_boundary_section.get_shared_sub_segments():\n",
    "                split_geometry = wrapper.wrap(shared_sub_segment.get_geometry())\n",
    "                for geometry in split_geometry:\n",
    "                    X=[]\n",
    "                    Y=[]\n",
    "                    for point in geometry.get_points():\n",
    "                        X.append(point.get_longitude()),Y.append(point.get_latitude())\n",
    "                    x,y = X,Y\n",
    "                    subductions.append([x,y])\n",
    "        elif shared_boundary_section.get_feature().get_feature_type() == pygplates.FeatureType.create_gpml('SubductionZone'):\n",
    "            for shared_sub_segment in shared_boundary_section.get_shared_sub_segments():\n",
    "                split_geometry = wrapper.wrap(shared_sub_segment.get_geometry())\n",
    "                for geometry in split_geometry:\n",
    "                    X=[]\n",
    "                    Y=[]\n",
    "                    for point in geometry.get_points():\n",
    "                        X.append(point.get_longitude()),Y.append(point.get_latitude())\n",
    "                    x,y = X,Y\n",
    "                    oceanRidges.append([x,y])\n",
    "        else: \n",
    "            for shared_sub_segment in shared_boundary_section.get_shared_sub_segments():\n",
    "                split_geometry = wrapper.wrap(shared_sub_segment.get_geometry())\n",
    "                for geometry in split_geometry:\n",
    "                    X=[]\n",
    "                    Y=[]\n",
    "                    for point in geometry.get_points():\n",
    "                        X.append(point.get_longitude()),Y.append(point.get_latitude())\n",
    "                    x,y = X,Y\n",
    "                    otherBounds.append([x,y])   \n",
    "    return subductions, oceanRidges, otherBounds\n",
    "\n",
    "def plotElev(time, data, subductions, oceanRidges, otherBounds, out_path):\n",
    "    fig = pygmt.Figure()\n",
    "    with pygmt.config(FONT='6p,Helvetica,black'):\n",
    "        pygmt.makecpt(cmap=\"geo\", series=[-6000, 6000])\n",
    "        fig.basemap(region='d', projection='W6i', frame='afg')\n",
    "        viewset = data.z\n",
    "        fig.grdimage(viewset, shading=True, frame=False)\n",
    "#         fig.grdcontour(interval=0.1,grid=viewset,limit=[-0.1, 0.1])\n",
    "        fig.colorbar(position=\"jBC+o0c/-1.5c+w8c/0.3c+h\",frame=[\"a2000\", \"x+lElevation\", \"y+lm\"])\n",
    "\n",
    "        for k in range(len(subductions)):\n",
    "            fig.plot(x=subductions[k][0], y=subductions[k][1], \n",
    "                     pen=\"1p,red\", \n",
    "                     transparency=\"0\")\n",
    "\n",
    "        for k in range(len(oceanRidges)):\n",
    "            fig.plot(x=oceanRidges[k][0], y=oceanRidges[k][1], \n",
    "                     pen=\"1p,white\", \n",
    "                     transparency=\"0\")\n",
    "\n",
    "        for k in range(len(otherBounds)):\n",
    "            fig.plot(x=otherBounds[k][0], y=otherBounds[k][1], \n",
    "                     pen=\"1p,purple\", \n",
    "                     transparency=\"0\")\n",
    "\n",
    "    # Customising the font style\n",
    "    fig.text(text=str(time)+\" Ma\", position=\"TL\", font=\"8p,Helvetica-Bold,black\") \n",
    "    fname = out_path+'/elev'+str(time)+'Ma.png'\n",
    "    fig.savefig(fname=fname,dpi=500)\n",
    "#     fig.show(dpi=500, width=1000)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb6e54",
   "metadata": {},
   "source": [
    "Save the paleo-elevation as `png` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449fd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = np.arange(100,-1,-1)\n",
    "\n",
    "rotation_fname = 'PALEOMAP_PlateModel.rot'\n",
    "polygon_fname = 'PlateBoundaries.gpml'\n",
    "out_elev = 'forward'\n",
    "\n",
    "rotationModel = pygplates.RotationModel(rotation_fname)\n",
    "topoFeature = pygplates.FeatureCollection(polygon_fname)\n",
    "\n",
    "for k in range(len(stime)):\n",
    "    subductions, oceanRidges, otherBounds = getBounds(int(stime[k]), topoFeature, rotationModel)\n",
    "    elevfile = out_elev+'/ndem'+str(stime[k])+'Ma.nc'\n",
    "    data = xr.open_dataset(elevfile)\n",
    "    plotElev(stime[k], data, subductions, oceanRidges, otherBounds, out_elev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f854780",
   "metadata": {},
   "source": [
    "Save as a movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = np.arange(100,-1,-1)\n",
    "out_elev = 'forward'\n",
    "images = []\n",
    "for k in range(len(stime)):\n",
    "    filename = out_elev+'/elev'+str(int(stime[k]))+'Ma.png'\n",
    "    images.append(imageio.imread(filename))\n",
    "                                    \n",
    "imageio.mimsave('elev1Ma.mp4', images, fps=1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
